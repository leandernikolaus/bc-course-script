%!TEX root = ../main.tex

\noindent
In the Bitcoin protocol, any node can join. Additional any entity can create multiple accounts on bitcoin. Accounts are per default anonymous.
This model is called \textbf{unpermissioned}. No permission is needed to participate. 

\section{Unpermissioned systems}
In an unpermissioned or permissionless system anyone can join, usually anonymity is provided.
Thus the creation of sybils is usually possible.

To mitigate the existence of sybils, unpermissioned blockchains use Proof of Work or Proof of Stake or similar mechanisms.

\section{Permissioned systems}
Permissioned systems assume there exists a list of members.
New members need permission or authentication via a central authority to join. 
Table~\ref{tab:members} gives an example of a table of members.. Typically assume that all members have a copy of the membership list. 

The existence of a membership list, or possibility to create and distribute one
is often referred to as public key infrastructure (PKI).
It allows any two members to contact each other (using listed IP addresses), and create an authenticated channel (using public keys).

\begin{table}[h]
	\centering
	\begin{tabular}{| c | c | c | c | }
		\hline
		ID & $pubkey$ & IP & ... \\
		\hline
		1 & 0x1f3 & &\\
		\hline
		2 & 21xf3 & &\\
		\hline
		
	\end{tabular}
	\caption{Membership list example. \label{tab:members}}
\end{table}

In a permissioned system the central authority prevents sybils.

\begin{example}
	\begin{enumerate}
		\item The classical example for a permissioned blockchain is a blockchain run together by a set of organizations. Typically, we assume that each organization runs a node. The Libra/Diem blockchain is an example for this. For Libra, a non-profit central organization exists, which is functioning as central authority.
		\item If a single system, run within one organization is running on multiple servers, this also is a permissioned system. The different servers have unique ids and the system administrator functions as central authority.
		\item A more open example is a system that requires nodes to authenticate with Bank-ID, passport or sharing their social media activity. 
		Here the central authority is the issuer of Bank-ID, passport or social media.
	\end{enumerate}
\end{example}


\section{Failure models}
We distinguish different failure models, based on the failure assumptions, e.g. what failures may happen.
All apply to permissioned systems, some are applicable to unpermissioned systems.

\paragraph{No failure}
Assuming that members do not fail, it is possible to use authenticated channels for trusted interactions.

\paragraph{Central node does not fail}
Given a centralized node, that processes trust to not fail, they can build a centralized system, where the trusted node is responsible to manage state and interaction for the other members.

This model is used in cloud services, where all users connect to the service provider and trust this provider to store and maintain their application state and coordinate interactions with other users.

\paragraph{Crash failure}
In this model, nodes can stop by crash failures. It is not possible to communicate with a crashed node and the data stored on a crashed node may be lost.

This model is often assumed for machines that cooperatively run a service within a trusted domain, e.g. servers within a data center. 

In this model it is possible to implement consistent services, e.g. a blockchain, that work as long as a majority of the nodes is running. Examples are the Paxos algorithm thaught in DAT520.

In this model, as shown by the Paxos algorithm it is possible to develop systems that simply halt, when the failure threshold is violated.
Thus, even if a majority of nodes fail, nothing bad will happen.

\paragraph{Byzantine fault tolerance BFT}
It is assumed that \emph{any node may fail or misbehave}, i.e. a faulty node may not only stop, but may act maliciously, trying to sabotage the application. However, it is assumed that \emph{only a small fraction of the nodes actually fail or misbehave}.

Misbehavior may for example be caused by 
\begin{itemize}
	\item virus or malware
	\item misconfiguration
	\item sabotage
\end{itemize}
The above assumption says, that at most a small fraction of the nodes will be victim to any of these.

In this model it is possible to implement consistent services, e.g. a blockchain, that works as long as a large majority, e.g. 2/3 of the members are correct.

\paragraph{Selfish or rational misbehavior}
All nodes could misbehave if it benefits them. Such nodes are called \emph{selfish} or \emph{rational}.
Different from the BFT model, we do not assume a failure threshold, but we assume, nodes will not misbehave if this is not in their interest.

In this model it is possible to design algorithms using game theory. 
For this, every node is assigned a utility function:

For example the utility of participating in bitcoin mining is the block reward and transaction fees, minus costs for computation and networking, e.g. energy and hardware.

The goal for game theory is to show that nodes cannot increase their utility, by deviating from a protocol, e.g. by deviating from the longest chain rule.

\begin{definition}
In game theory we assume that agents or players are free to choose from different actions. The set of actions an agent takes are called a \textbf{strategy}.
\end{definition}

In traditional game theory we assume that games are deterministic, meaning that given a set of strategies, one for every agent, we can determine what will be the utility of every agent.

\begin{definition}
	A \textbf{Nash-Equilibrium} is a set of strategies, one for every agent, such that no individual agent can improve his utility, by choosing a different strategy.
\end{definition}

For a protocol it is desirable that for every node to follow the protocol is a Nash-Equilibrium. This means that agents will not profit in utility by deviating from the protocol.

However, note that the notion of Nash-Equilibrium does not exclude the possibility that coalitions may successfully deviate.

\begin{note}
There exists variants of the Nash-Equilibrium that take into account, e.g. the possibility for small coalitions, the fact that agents may only deviate if it gives a significant benefit, or the fact that a game may be probabilistic.
\end{note}